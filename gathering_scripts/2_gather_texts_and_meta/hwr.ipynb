{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook for experiments in gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = '../../raw_data/film_media_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_path)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"hollywood_reporter\")\n",
    "hwr_article_class_name = \"article__body js-fitvids-content\"\n",
    "hwr_meta_names = ['title', 'description', 'date', 'author', 'vertical', 'tags']\n",
    "hwr_df = df.loc[df.media == \"hollywood_reporter\"]\n",
    "#hwr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "def get_html(url):\n",
    "    fake_headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    response = requests.get(url, headers=fake_headers)\n",
    "    return response.text\n",
    "\n",
    "def get_html_test():\n",
    "    hwr_test_url = 'https://www.hollywoodreporter.com/news/elle-fanning-uma-thurman-diane-kruger-hit-pradas-resort-2020-show-1207308'\n",
    "    return get_html(hwr_test_url)\n",
    "\n",
    "#print(get_html_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bs4 import BeautifulSoup\n",
    "def get_article_text(html_text, class_name_str):\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "    mydivs = soup.find(\"div\", {\"class\": class_name_str})\n",
    "    text = ''\n",
    "    for p in mydivs.find_all(\"p\"):\n",
    "        text += p.text + ' '\n",
    "    return text\n",
    "\n",
    "def get_article_meta(html_text, meta_names):\n",
    "    ret = {}\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "    for name in meta_names:        \n",
    "        ret[name] = soup.find(\"meta\", {\"name\": \"sailthru.\"+name})['content']\n",
    "    return ret\n",
    "\n",
    "def get_article_text_test():    \n",
    "    hwr_test_url = 'https://www.hollywoodreporter.com/news/elle-fanning-uma-thurman-diane-kruger-hit-pradas-resort-2020-show-1207308'\n",
    "    hwr_html_text = get_html(hwr_test_url)\n",
    "    return get_article_text(hwr_html_text, hwr_article_class_name)\n",
    "\n",
    "def get_article_meta_test():    \n",
    "    hwr_test_url = 'https://www.hollywoodreporter.com/news/elle-fanning-uma-thurman-diane-kruger-hit-pradas-resort-2020-show-1207308'\n",
    "    hwr_html_text = get_html(hwr_test_url)\n",
    "    return get_article_meta(hwr_html_text, ['title', 'description', 'date', 'author', 'vertical', 'tags'])\n",
    "\n",
    "#get_article_meta_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_article_urls(df):    \n",
    "    modified_df = df\n",
    "    # expand dataframe, add columns for meta\n",
    "    warnings.filterwarnings('ignore')\n",
    "    for meta_name in hwr_meta_names:\n",
    "        modified_df[meta_name] = None\n",
    "    warnings.filterwarnings('always')\n",
    "        \n",
    "    cannot_parsed = {} # {url : reason}\n",
    "    with tqdm(desc=\"rows\", total=len(df)) as pbar_outer:\n",
    "        for row in df.itertuples():\n",
    "            url = getattr(row, 'article_url')\n",
    "            # part 0: get html text\n",
    "            html_text = None\n",
    "            try:\n",
    "                html_text = get_html(url)\n",
    "            except:\n",
    "                cannot_parsed[url] = 'cannot get html'\n",
    "                pbar_outer.update(1)\n",
    "                continue                \n",
    "            # part 1: get article text\n",
    "            article_text = None\n",
    "            try:\n",
    "                article_text = get_article_text(html_text, hwr_article_class_name)                          \n",
    "            except:\n",
    "                cannot_parsed[url] = 'cannot get text'\n",
    "                pbar_outer.update(1)\n",
    "                continue\n",
    "            # part 2: get article meta\n",
    "            article_meta = None\n",
    "            try:\n",
    "                article_meta = get_article_meta(html_text, hwr_meta_names)\n",
    "            except:\n",
    "                cannot_parsed[url] = 'cannot get meta'\n",
    "                pbar_outer.update(1)\n",
    "                continue\n",
    "            # part 3: save data\n",
    "            try:\n",
    "                for meta_name in hwr_meta_names:\n",
    "                    modified_df.at[getattr(row,'Index'),meta_name] = article_meta[meta_name]\n",
    "                file = open(getattr(row,'text_path'),'w')\n",
    "                file.write(article_text)  \n",
    "                file.close()\n",
    "            except:\n",
    "                cannot_parsed[url] = 'cannot save data'\n",
    "            pbar_outer.update(1)\n",
    "            break\n",
    "    return (modified_df, cannot_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rows:   0%|          | 1/101918 [00:00<7:54:51,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "mod_hwr_df, errors = parse_article_urls(hwr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if len(errors)>0:\n",
    "    file = open(f'{media_name}_errors.csv', \"w\")\n",
    "    f = csv.writer(file)\n",
    "    f.writerow([\"url\", \"reason\"])\n",
    "    for key, value in errors.items():\n",
    "      f.writerow([key, value])\n",
    "    file.close()\n",
    "    \n",
    "mod_hwr_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod_hwr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_hwr_df.to_csv(\"mod_hwr_df.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
